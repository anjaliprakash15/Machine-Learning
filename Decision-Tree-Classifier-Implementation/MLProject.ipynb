{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6PxzeUyIlYYr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read dataset\n",
        "def read_dataset(file_path):\n",
        "    dataset = pd.read_csv(file_path, header=None)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Ygwh57cWlc0R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle missing values\n",
        "def process_missing_values(train_set, test_set):\n",
        "    for column in train_set.columns:\n",
        "        if train_set[column].dtype == 'O':  # Categorical attribute\n",
        "            sorted_vals = sorted(train_set[column].dropna().unique())\n",
        "            median_val = sorted_vals[len(sorted_vals) // 2] if sorted_vals else None\n",
        "        else:  # Continuous attribute\n",
        "            median_val = train_set[column].median()\n",
        "\n",
        "        if median_val is not None:\n",
        "            train_set[column] = train_set[column].fillna(median_val)\n",
        "            test_set[column] = test_set[column].fillna(median_val)\n",
        "\n",
        "    return train_set, test_set"
      ],
      "metadata": {
        "id": "wvWiF935l8ix"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate entropy\n",
        "def compute_entropy(labels):\n",
        "    values, counts = np.unique(labels, return_counts=True)\n",
        "    probabilities = counts / counts.sum()\n",
        "    return -np.sum(probabilities * np.log2(probabilities))"
      ],
      "metadata": {
        "id": "FHXlDtHGmADI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute Gini index\n",
        "def compute_gini(labels):\n",
        "    values, counts = np.unique(labels, return_counts=True)\n",
        "    probabilities = counts / counts.sum()\n",
        "    return 1 - np.sum(probabilities ** 2)"
      ],
      "metadata": {
        "id": "8om3OTUTmDjI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to divide dataset based on an attribute\n",
        "def divide_dataset(dataset, attr_index, split_value):\n",
        "    left_subset = dataset[dataset.iloc[:, attr_index] <= split_value]\n",
        "    right_subset = dataset[dataset.iloc[:, attr_index] > split_value]\n",
        "    return left_subset, right_subset"
      ],
      "metadata": {
        "id": "0uRlHxvemJL8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine best split for C4.5 algorithm\n",
        "def find_best_split_c45(dataset):\n",
        "    features, labels = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
        "    initial_entropy = compute_entropy(labels)\n",
        "    optimal_gain_ratio, optimal_feature, optimal_split = -1, None, None\n",
        "\n",
        "    for feature in range(features.shape[1]):\n",
        "        split_values = np.unique(features.iloc[:, feature])\n",
        "        for split in split_values:\n",
        "            left_part, right_part = divide_dataset(dataset, feature, split)\n",
        "            if len(left_part) == 0 or len(right_part) == 0:\n",
        "                continue\n",
        "\n",
        "            left_entropy = compute_entropy(left_part.iloc[:, -1])\n",
        "            right_entropy = compute_entropy(right_part.iloc[:, -1])\n",
        "            weighted_entropy = (len(left_part)/len(labels)) * left_entropy + (len(right_part)/len(labels)) * right_entropy\n",
        "            info_gain = initial_entropy - weighted_entropy\n",
        "\n",
        "            intrinsic_value = -((len(left_part)/len(labels)) * np.log2(len(left_part)/len(labels)) + (len(right_part)/len(labels)) * np.log2(len(right_part)/len(labels))) if len(left_part) > 0 and len(right_part) > 0 else 1\n",
        "            gain_ratio = info_gain / intrinsic_value if intrinsic_value != 0 else 0\n",
        "\n",
        "            if gain_ratio > optimal_gain_ratio:\n",
        "                optimal_gain_ratio, optimal_feature, optimal_split = gain_ratio, feature, split\n",
        "\n",
        "    return optimal_feature, optimal_split\n"
      ],
      "metadata": {
        "id": "PqLQueXomTGX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine best split for CART algorithm\n",
        "def find_best_split_cart(dataset):\n",
        "    features, labels = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
        "    optimal_gini, optimal_feature, optimal_split = float('inf'), None, None\n",
        "\n",
        "    for feature in range(features.shape[1]):\n",
        "        split_values = np.unique(features.iloc[:, feature])\n",
        "        for split in split_values:\n",
        "            left_part, right_part = divide_dataset(dataset, feature, split)\n",
        "            if len(left_part) == 0 or len(right_part) == 0:\n",
        "                continue\n",
        "\n",
        "            weighted_gini = (len(left_part)/len(labels)) * compute_gini(left_part.iloc[:, -1]) + (len(right_part)/len(labels)) * compute_gini(right_part.iloc[:, -1])\n",
        "\n",
        "            if weighted_gini < optimal_gini:\n",
        "                optimal_gini, optimal_feature, optimal_split = weighted_gini, feature, split\n",
        "\n",
        "    return optimal_feature, optimal_split"
      ],
      "metadata": {
        "id": "YxOVjiCRmWSb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class for tree nodes\n",
        "class TreeNode:\n",
        "    def __init__(self, attribute=None, split_value=None, left_branch=None, right_branch=None, outcome=None):\n",
        "        self.attribute = attribute\n",
        "        self.split_value = split_value\n",
        "        self.left_branch = left_branch\n",
        "        self.right_branch = right_branch\n",
        "        self.outcome = outcome"
      ],
      "metadata": {
        "id": "Acu4jYfimZYO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class to build decision trees\n",
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, method=\"c45\", max_depth=10):\n",
        "        self.method = method\n",
        "        self.max_depth = max_depth\n",
        "        self.root = None\n",
        "\n",
        "    def construct_tree(self, dataset, depth=0):\n",
        "        labels = dataset.iloc[:, -1]\n",
        "        if len(np.unique(labels)) == 1 or depth >= self.max_depth:\n",
        "            return TreeNode(outcome=labels.iloc[0])\n",
        "\n",
        "        feature, split = find_best_split_c45(dataset) if self.method == \"c45\" else find_best_split_cart(dataset)\n",
        "        if feature is None:\n",
        "            return TreeNode(outcome=labels.mode()[0])\n",
        "\n",
        "        left_subset, right_subset = divide_dataset(dataset, feature, split)\n",
        "        left_branch = self.construct_tree(left_subset, depth+1)\n",
        "        right_branch = self.construct_tree(right_subset, depth+1)\n",
        "\n",
        "        return TreeNode(feature, split, left_branch, right_branch)\n",
        "\n",
        "    def train(self, dataset):\n",
        "        self.root = self.construct_tree(dataset)\n",
        "\n",
        "    def classify_instance(self, node, instance):\n",
        "        if node.outcome is not None:\n",
        "            return node.outcome\n",
        "        if instance[node.attribute] <= node.split_value:\n",
        "            return self.classify_instance(node.left_branch, instance)\n",
        "        return self.classify_instance(node.right_branch, instance)\n",
        "\n",
        "    def classify(self, features):\n",
        "        return np.array([self.classify_instance(self.root, row) for _, row in features.iterrows()])\n"
      ],
      "metadata": {
        "id": "s1A535rNmbJh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and clean datasets\n",
        "training_set = read_dataset(\"/content/training.data\")\n",
        "testing_set = read_dataset(\"/content/test.data\")\n",
        "training_set, testing_set = process_missing_values(training_set, testing_set)"
      ],
      "metadata": {
        "id": "npb9zydlmjyU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_cross_validation(data, method):\n",
        "    kf = KFold(n_splits=10, shuffle=False)\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(data):\n",
        "        train_fold = data.iloc[train_idx]\n",
        "        val_fold = data.iloc[val_idx]\n",
        "\n",
        "        tree = DecisionTreeClassifier(method)\n",
        "        tree.train(train_fold)\n",
        "\n",
        "        predictions = tree.classify(val_fold.iloc[:, :-1])\n",
        "        f1 = f1_score(val_fold.iloc[:, -1], predictions, average=\"binary\", pos_label=\"+\")\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    return np.mean(f1_scores)\n",
        "\n",
        "# Cross-validation for both models\n",
        "best_f1_c45 = perform_cross_validation(training_set, \"c45\")\n",
        "best_f1_cart = perform_cross_validation(training_set, \"cart\")\n",
        "\n",
        "#Print the results\n",
        "print(f\"F1-score of c45: {best_f1_c45:.4f}\")\n",
        "print(f\"F1-score of cart: {best_f1_cart:.4f}\")\n",
        "\n",
        "# Select the best model\n",
        "best_method = \"c45\" if best_f1_c45 > best_f1_cart else \"cart\"\n",
        "print(f\"Best model after cross-validation: {best_method.upper()} (F1-score: {max(best_f1_c45, best_f1_cart):.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFe7zFF2n8mw",
        "outputId": "83cc8dc4-1f66-4578-afc4-78a2e8f097f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score of c45: 0.8044\n",
            "F1-score of cart: 0.8014\n",
            "Best model after cross-validation: C45 (F1-score: 0.8044)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model on the full training set\n",
        "final_tree = DecisionTreeClassifier(best_method)\n",
        "final_tree.train(training_set)\n",
        "\n",
        "# Evaluate on the test set\n",
        "final_predictions = final_tree.classify(testing_set.iloc[:, :-1])\n",
        "final_accuracy = accuracy_score(testing_set.iloc[:, -1], final_predictions)\n",
        "final_f1 = f1_score(testing_set.iloc[:, -1], final_predictions, average=\"binary\", pos_label=\"+\")\n",
        "print(f\"Final {best_method.upper()} Model Accuracy on Test Set: {final_accuracy:.4f}\")\n",
        "print(f\"Final {best_method.upper()} Model F1-Score on Test Set: {final_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AACG1t_YrAXY",
        "outputId": "75fd3659-60e6-4b2a-bcee-779b14ed36f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final C45 Model Accuracy on Test Set: 0.8429\n",
            "Final C45 Model F1-Score on Test Set: 0.8254\n"
          ]
        }
      ]
    }
  ]
}